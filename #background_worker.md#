# Processing Payments with Background Workers

[stripe]: https://stripe.com/docs/tutorials/checkout
[guide]: /payment-integration.html
[docs]: https://stripe.com/docs/api
[sucker_punch]: https://github.com/brandonhilkert/sucker_punch
[Celluloid]: https://github.com/celluloid/celluloid/
[redis]: http://redis.io
[dj]: https://github.com/collectiveidea/delayed_job
[sidekiq]: http://sidekiq.org
[mperham]: http://www.mikeperham.com
[qc]: https://github.com/ryandotsmith/queue_classic

Processing payments correctly is hard. This is one of the biggest lessons I've learned while writing my various [SaaS projects](/projects.html). Stripe does everything they can to make it easy, with [quick start guides][stripe] and [great documentation][docs]. One thing they really don't cover in the docs is what to do if your connection with their API fails for some reason. Processing payments inside a web request is asking for trouble, and the solution is to run them using a background job. 

## The Problem

Let's take Stripe's example code:

```ruby
Stripe.api_key = ENV['STRIPE_API_KEY']

token = params[:stripeToken]

begin
  charge = Stripe::Charge.create(
    :amount => 1000, # amount in cents, again
    :currency => "usd",
    :card => token,
    :description => "payinguser@example.com"
  )
rescue Stripe::CardError => e
  # The card has been declined
end
```
    
Pretty straight-forward. Using the `stripeToken` that `stripe.js` inserted into your form, create a charge object. If this fails due to a `CardError`, you can safely assume that the customer's card got declined. Behind the scenes, `Stripe::Charge` makes an `https` call to Stripe's API. Typically, this completes almost immediately.

But what if it doesn't? The internet between your server and Stripe's could be slow or down. DNS resolution could be failing. There's a million reasons why this code could take awhile. Browsers typically have around a one minute timeout and application servers like Unicorn usually will kill the request after 30 seconds. That's a long time to keep the user waiting just to end up at an error page.

## The Solution

The solution is to put the call to `Stripe::Charge.create` in a background job. By separating the work that can fail or take a long time from the web request we insulate the user from timeouts and errors while giving our app the ability to retry (if possible) or tell us something failed (if not). 

There's a bunch of different background worker systems available for Rails and Ruby in general, scaling all the way from simple in-process threaded workers with no persistence to external workers persisting jobs to the database or [Redis][redis], then even further to message busses like AMQP, which are overkill for what we need to do.

### In-Process

One of the best in-process workers that I've come across is called [Sucker Punch][sucker_punch]. Under the hood it uses the actor model to safely use concurrent threads for work processing, but you don't really have to worry about that. It's pretty trivial to use, just include the `SuckerPunch::Worker` module into your worker class, declare a queue using that class, and chuck jobs into it. In `app/workers/banana_worker.rb`:

```ruby
class BananaWorker
  include SuckerPunch::Worker

  def perform(event)
    puts "I am a banana!"
  end
end
```

In `config/initializers/queues.rb`:

```ruby
SuckerPunch.config do
  queue name: :banana_queue, worker: BananaWorker, workers: 10
end
```

Then, in a controller somewhere:

```ruby
SuckerPunch::Queue[:banana_queue].async.perform("hi")
```

The drawback to Sucker Punch, of course, is that if the web process falls over then your jobs evaporate. This will happen, no two ways about it. Errors and deploys will both kill the web process and erase your jobs.

### Database Persistence

The classic, tried-and-true background worker is called [Delayed Job][dj]. It's been around since 2008 and is battle tested and production ready. At my day job we use it to process hundreds of thousands of events every day and it's basically fire and forget. It's also easier to use than Sucker Punch. Assuming a class like this:

```ruby
class Banana
  def initialize(size)
    @size = size
  end

  def split
    puts "I am a banana split, #{@size} size!"
  end
end
```

To queue the `#split` method in a background job, all you have to do is:

```ruby
Banana.new('medium').delay.split
```

That is, put a call to `delay` before the call to `split`. Delayed Job will serialize the object, put it in the database, and then when a worker is ready to process the job it'll do the reverse and finally run the `split` method.

To work pending jobs, just run

```bash
$ bundle exec rake jobs:work
```

Delayed Job does have some drawbacks. First, because it stores jobs in the same database as everything else it has to content with everything else. For example, your database serve almost certainly has a limit on the number of connections it can handle, and every worker will require two of them, one for Delayed Job itself and another for any ActiveRecord objects. Second, it can get tricky to backup because you really don't need to be backing up the jobs table. That said, it's relatively simple and straight forward and has the distinct advantage of not making you run any new external services.

Another PostgreSQL-specific database backed worker system is [Queue Classic][qc], which leverages some specific features that PostgreSQL provides to workers very efficient. Specifically it uses `listen` and `notify`, the built-in publish/subscribe system, to tell workers when there are jobs to be done so they don't have to poll. It also uses row-level locking to reduce database load and ensure only one worker is working a job at any given time.

### Redis

[Redis][redis] bills itself as a "networked data structure server". It's a database server that provides rich data types like lists, queues, sets, and hashes, all while being extremely fast because everything is in-memory all the time. The best Redis-based background worker, in my opinion, is [Sidekiq][sidekiq] written by [Mike Perham][mperham]. It uses the same actor-based concurrency library under the hood as Sucker Punch, but because it stores jobs in Redis it can also provide things like a beautiful management console and fine-grained control over jobs. The setup is essentially identical to Sucker Punch:

```ruby
class BananaWorker
  include Sidekiq::Worker

  def perform(event)
    puts "I am a banana!"
  end
end
```

Then in a controller:

```ruby
BananaWorker.perform_async("hi")
```

To work jobs, fire up Sidekiq:

```bash
$ bundle exec sidekiq
```

<hr>

For this example we're going to use Sidekiq. If you'd like to use one of the other job systems described above, or if you already have your own for other things, it should be trivial to change.

First, let's create a job class:

```ruby
class StripeCharger
  include Sidekiq::Worker

  def perform(guid)
    ActiveRecord::Base.connection_pool.with_connection do
      sale = Sale.find(guid)
      sale.process!
    end
  end
end
```

Again, pretty straightforward. Sidekiq will create an instance of your job class and call `#perform` on it with a hash of values that you pass in to the queue, which we'll get to in a second. We look up the relevant `Sale` record and tell it to process using the state machine event we set up earlier using `AASM`. 

Now, in the TransactionsController, replace the transaction processing code with a call to `perform_async`, like so:

```ruby
class TransactionsController < ApplicationController

  def create
    product = Product.where(permalink: params[:permalink]).first
    raise ActionController::RoutingError.new("Not found") unless product

    token = pa

    txn = Sale.new(
      amount: 1000,
      email: params[:email],
      stripe_token: params[:stripeToken]
      product_id:
    )
    if txn.save
      StripCharger.perform_async(
        transaction_id: txn.id,
        token: params[:stripeToken]
      )
      render json: txn.to_json
    else
      render json: {error: txn.error_messages}, status: 422
    end
  end
  
  def show
    txn = Transaction.find(params[:id])
    raise ActionController::RoutingError.new('not found')
      unless txn

    render json: txn.to_json
  end
end
```

The `create` method creates a new `Transaction` record, setting it's state to `pending`. It then queues the transaction to be processed by `StripeCharger`. The `show` method simply looks up the transaction and spits back some JSON. On your customer-facing page you'd do something like this:

```javascript
function doPoll(id){
    $.get('/transactions/' + id, function(data) {
        if (data.state === "complete") {
          window.location = '/thankyou';
        } elsif (data.state === "failed") {
          handleFailure(data);
        } else {
          setTimeout(function(){ doPoll(id); }, 500);
        }
    });
}
```
    
Your page will poll `/transactions/<id>` until the transaction ends in either success or failure. You'd probably want to show a spinner or something to the user while this is happening.

With this setup, you've insulated yourself from problems in your connection to Stripe, your connection to your customer, and everything in between.
